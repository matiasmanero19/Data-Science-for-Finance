{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit (conda)",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "e8d487457057c6eff5f8c11de86e4fe7d7b168c146070c45a573d3a57a3717df"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/UCEMA-QUANt/Data-Science-for-Finance/blob/master/04_preprocesamiento_sklearn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Scikit Learn\n",
    "\n",
    "Desde hace años, Scikit Learn es el estándar de facto en términos de paquetes de utilidades y algoritmos de aprendizaje automático. Si bien en los últimos tiempos, tanto en gradient boosting como en deep learning, han surgido otros paquetes que son más populares en determinados contextos, esta librería sigue teniendo toda la funcionalidad de soporte para desarrollar y automatizar procesos de entrenamiento y predicción.\n",
    "\n",
    "Iremos viendo este paquete de una manera funcional, a través de las tareas propias de un proceso de desarrollo e implementación de aprendizaje automático.\n",
    "\n",
    "#### *Nota sobre la API de sklearn*: la gran mayoría de algoritmos y utilidades son clases que se instancia llamándola como una función con parámetro de inicialización y luego tiene dos métodos, `fit` para entrenar el algoritmo y `transform` o `predict` para aplicarlo, según el caso y la utilidad. Existen algunas funciones simples también para funcionalidades más sencillas. \n",
    "\n",
    "## 1. Pre-procesado\n",
    "\n",
    "Luego de la lectura de datos que ya vimos con `Pandas`, la primera tarea de manipulación de datos suele ser el preprocesador, que consiste en la transformación de los datos para que sean procesables y/o más compatibles con el algoritmo elegido o incluso que le permitan más poder explicativo.\n",
    "\n",
    "Las transformaciones para lograr que -algunos algoritmos- puedan procesar los datos son la `asignación de nulos` y, en menor medida, la `codificación de variables no intervalares (categóricas y ordinales) `; mientras que el `escalado y normalización` tiene a lograr una mejor compatibilidad con ciertos modelos. Por otro lado, la creación de variables, aunque contiene una gran parte de arte, es una forma muy potente de agregar poder explicativo al modelo.\n",
    "\n",
    "Veremos estas técnicas en el orden lógico de su utilización, aunque algunas, particularmente las que operan sobre columnas independientes como el escalado y la codificación, son intercambiables.\n",
    "\n",
    "Asimismo, existen algunas técnicas como la discretización (bins) o la transformación binaria que ya no se usan a menudo; al igual que técnicas de detección de valores extremos (`outliers`) y reducción de dimensionalidad que no tienen a tener ya los mismos beneficios que en otras épocas con menos capacidad de cálculo y algoritmos menos sofisticados. \n",
    "\n",
    "### A.- Asignación de nulos o perdidos\n",
    "\n",
    "Excepto alguna implementación de `gradient boosting`, todos los algoritmos de aprendizaje automático son incompatibles con la existencia de nulos en el dataset. \n",
    "\n",
    "Con los valores perdidos hay que ser especialmente cuidadoso, porque a veces tienen de por si un sentido, es decir que no son al azar. Si es así, hay que buscar una forma lógica de completarlos. Si no, se pueden completar de alguna formas distintas.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c0   c1    c2   c3\n",
       "0  1.0  2.0   3.0  NaN\n",
       "1  NaN  NaN   NaN  0.0\n",
       "2 -5.0  0.0  25.0  NaN\n",
       "3  1.0 -1.0   NaN  NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "X = pd.DataFrame([\n",
    "    [1,2,3,np.nan],\n",
    "    [np.nan, np.nan, np.nan, 0],\n",
    "    [-5, 0, 25, np.nan],\n",
    "    [1,-1, np.nan, np.nan]\n",
    "], columns=[f\"c{i}\" for i in range(4)])\n",
    "X"
   ]
  },
  {
   "source": [
    "# forma 1 eliminar filas o columnas con muchos nulos\n",
    "X.dropna(axis=0, thresh=3)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c0   c1    c2  c3\n",
       "0  1.0  2.0   3.0 NaN\n",
       "2 -5.0  0.0  25.0 NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c0   c1    c2\n",
       "0  1.0  2.0   3.0\n",
       "1  NaN  NaN   NaN\n",
       "2 -5.0  0.0  25.0\n",
       "3  1.0 -1.0   NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X.dropna(axis=1, thresh=int(X.shape[0] / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      c0     c1     c2     c3\n",
       "0    1.0    2.0    3.0  999.0\n",
       "1  999.0  999.0  999.0    0.0\n",
       "2   -5.0    0.0   25.0  999.0\n",
       "3    1.0   -1.0  999.0  999.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>999.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>999.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#completar con algun valro testigo fuera del rango de valores.abs\n",
    "X.fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c0   c1    c2   c3  c2null\n",
       "0  1.0  2.0   3.0  NaN   False\n",
       "1  NaN  NaN   NaN  0.0    True\n",
       "2 -5.0  0.0  25.0  NaN   False\n",
       "3  1.0 -1.0   NaN  NaN    True"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c2null</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X[\"c2null\"] = X.c2.isnull()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.        ,  3.        ,  0.        ,  0.        ],\n",
       "       [-1.        ,  0.33333333, 14.        ,  0.        ,  1.        ],\n",
       "       [-5.        ,  0.        , 25.        ,  0.        ,  0.        ],\n",
       "       [ 1.        , -1.        , 14.        ,  0.        ,  1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#media\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X)\n",
    "res = imputer.transform(X)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.0, 2.0, 3.0, 0.0, False],\n",
       "       [1.0, -1.0, 3.0, 0.0, True],\n",
       "       [-5.0, 0.0, 25.0, 0.0, False],\n",
       "       [1.0, -1.0, 3.0, 0.0, True]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#moda\n",
    "SimpleImputer(strategy='most_frequent').fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.        ,  3.        ,  0.        ,  0.        ],\n",
       "       [-0.30826338,  0.33527936,  9.1484619 ,  0.        ,  1.        ],\n",
       "       [-5.        ,  0.        , 25.        ,  0.        ,  0.        ],\n",
       "       [ 1.        , -1.        ,  6.30000006,  0.        ,  1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#con un modelo\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputer.fit(X)\n",
    "imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c0   c1    c2   c3  c2null\n",
       "0  1.0  2.0   3.0  NaN   False\n",
       "1  NaN  NaN   NaN  0.0    True\n",
       "2 -5.0  0.0  25.0  NaN   False\n",
       "3  1.0 -1.0   NaN  NaN    True"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c2null</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c0   c1    c2   c3  c2null\n",
       "0  1.0  2.0   3.0  NaN   False\n",
       "1 -2.0  1.0  14.0  0.0    True\n",
       "2 -5.0  0.0  25.0  0.0   False\n",
       "3  1.0 -1.0  25.0  0.0    True"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c2null</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-2.0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[False, False, False,  True],\n",
       "       [ True,  True,  True, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True,  True]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "MissingIndicator(missing_values=999).fit_transform(X.fillna(999))"
   ]
  },
  {
   "source": [
    "### B.- Codificación de variables ordinales y categorías\n",
    "\n",
    "Los algoritmos no pueden procesar datos que formato texto o `string`, hay que transformarlos a números. Existen algunas opciones para codificar estas variables, dependiendo de su naturaleza. \n",
    "\n",
    "Si son ordinales, fácilmente se pueden traducir a número, en una escala arbitraria y solo manteniendo los ordenes y valores equidistantes. \n",
    "\n",
    "Si son categóricas, no es posible hacer lo mismo. Algunas implementaciones de gradient boosting toleran variables categorías, pero en general los demás no. Así que hay que omitirlas o transformarlas.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame([\n",
    "    ['M', 'CABA', 'medio'],\n",
    "    ['M', 'CABA', 'alto'],\n",
    "    ['F', 'PBA', 'alto'],\n",
    "    ['F', 'Córdoba', 'bajo'],\n",
    "    ['F', 'Córdoba', \"medio\"]\n",
    "], columns=[\"sexo\", \"provincia\", \"ingreso\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "OrdinalEncoder().fit_transform(X[[\"sexo\", \"ingreso\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrdinalEncoder().fit_transform(X[[\"sexo\", \"ingreso\"]].sort_values(\"sexo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(categories=[[\"F\", \"M\"], [\"bajo\", \"medio\", \"alto\"]])\n",
    "encoder.fit_transform(X[[\"sexo\", \"ingreso\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.inverse_transform([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.factorize(X.sexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificación dummy o one-hot\n",
    "OneHotEncoder().fit_transform(X[[\"sexo\", \"ingreso\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder().fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder().fit(X)\n",
    "pd.DataFrame(encoder.transform(X).toarray(), columns=[c for cc in encoder.categories_ for c in cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(encoder.transform(X).toarray(),\n",
    "            columns=[\n",
    "                f\"{column}_{category}\" for categories, column in zip(encoder.categories_, X.columns)\n",
    "                for category in categories\n",
    "            ])"
   ]
  },
  {
   "source": [
    "### C.- Escalado y normalización\n",
    "\n",
    "En casi todos los algoritmos basados en algebra (regresiones y redes neuronales), los parámetros del modelo se encuentran con alguna variante de `gradient descent` y por tanto adolecen se sensibilidad a la escala de los parámetros. Por ello, tiende a ser útil llevar a todas las variables a un rango parejo. Esto normalmente se logra con el escalado de cada columna para que estén en el mismo rango o tengan media y desvíos igual.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, Normalizer\n",
    "\n",
    "\n",
    "X = pd.DataFrame([\n",
    "    [1,-200,30000],\n",
    "    [2, 100, 50000],\n",
    "    [5,0, 100000]\n",
    "], columns=[f\"c{i}\" for i in range(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler().fit_transform(X).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler().fit_transform(X).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxAbsScaler().fit_transform(X)"
   ]
  },
  {
   "source": [
    "# la normalización es similar pero actua a nivel fila, y se usa cuadno vamos a usar algoritmos que miden distancias entre vectores\n",
    "\n",
    "Normalizer().fit_transform(X)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalizer().fit_transform(StandardScaler().fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformada = Normalizer().fit_transform(StandardScaler().fit_transform(X))\n",
    "np.square(transformada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(transormada).sum(axis=1)"
   ]
  },
  {
   "source": [
    "### Creación de Variables (Feature Engineering)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = pd.DataFrame([\n",
    "    [1,-20],\n",
    "    [2, 10],\n",
    "    [5,0]\n",
    "], columns=[f\"c{i}\" for i in range(2)])\n",
    "\n",
    "pd.DataFrame(PolynomialFeatures(2).fit_transform(X),\n",
    "             columns=[\"1\", \"c1\", \"c2\", \"c1^2\", \"c1*c2\", \"c2^2\"])"
   ]
  },
  {
   "source": [
    "### Tarea: leer los datos del titanic y transformarlos para lograr el mejor valor de la siguiente funcion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def metric(X):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.drop(\"Survived\", axis=1), X[\"Survived\"],\n",
    "                                                        test_size=0.25, random_state=42)\n",
    "    model = LogisticRegressionCV()\n",
    "    model.fit(X_train, y_train)\n",
    "    return log_loss(y_test,  model.predict_proba(X_test)), accuracy_score(y_test,  model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"../data/titanic.csv\", index_col=\"PassengerId\")\n",
    "except:\n",
    "    data = pd.read_csv(\"https://raw.githubusercontent.com/UCEMA-QUANt/Data-Science-for-Finance/master/data/titanic.csv\", index_col=\"PassengerId\")\n",
    "metric(data.fillna(99999).drop(data.select_dtypes(\"O\"), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(data[\"Survived\"],  np.zeros(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Cabin.fillna(\"NA\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Cabin.str[0].fillna(\"NA\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Name.str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Name.str.split(\",\").str[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Name.value_counts().value_counts()"
   ]
  }
 ]
}